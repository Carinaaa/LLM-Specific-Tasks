{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXWVka6B8iu+5GJZyB3q4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carinaaa/LLM-Specific-Tasks/blob/main/Ollama_collab_install.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b391f2d",
        "outputId": "185a967b-deeb-4eab-aeb5-8ba25a164506"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "# Download the Ollama installation script\n",
        "subprocess.run(['curl', '-fsSL', 'https://ollama.com/install.sh', '-o', 'install-ollama.sh'])\n",
        "\n",
        "# Make the script executable\n",
        "subprocess.run(['chmod', '+x', 'install-ollama.sh'])\n",
        "\n",
        "# Run the installation script\n",
        "# This might take a few moments\n",
        "subprocess.run(['./install-ollama.sh'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['./install-ollama.sh'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c30ff73",
        "outputId": "f1c659bb-a10f-4147-a4f3-6f67f10eec2a"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "# Start Ollama server as a background process using shell=True to interpret `nohup` and `&`\n",
        "# The `nohup` command ensures that the process continues to run even if the terminal is closed.\n",
        "# The `&` ensures it runs in the background, freeing up the current cell.\n",
        "# Redirecting output to /dev/null to prevent it from blocking the terminal output.\n",
        "subprocess.Popen('nohup ollama serve > /dev/null 2>&1 &', shell=True)\n",
        "\n",
        "print(\"Ollama server started in the background. Please wait a few seconds for it to fully initialize.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollama server started in the background. Please wait a few seconds for it to fully initialize.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cab26f",
        "outputId": "39dc89c0-930f-48e4-91a1-87cb9787c178"
      },
      "source": [
        "# Verify the installation by checking the Ollama version\n",
        "!ollama --version"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ollama version is 0.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a71fdd07",
        "outputId": "7852a1fc-f7d6-4a4c-ca5f-5d5802556ac0"
      },
      "source": [
        "!ps aux | grep ollama"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1289  7.3  0.3 2443768 52616 ?       Sl   08:27   0:28 ollama serve\n",
            "root        2529 22.2 44.2 7846832 5882316 ?     Sl   08:31   0:25 /usr/local/bin/ollama runner --model /root/.ollama/models/blobs/sha256-8934d96d3f08982e95922b2b7a2c626a1fe873d7c3b06e8e56d7bc0a1fef9246 --port 45665\n",
            "root        3046  0.0  0.0   7376  3416 ?        S    08:33   0:00 /bin/bash -c ps aux | grep ollama\n",
            "root        3048  0.0  0.0   6484  2428 ?        S    08:33   0:00 grep ollama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9726700d",
        "outputId": "978d55e3-6ebb-48aa-b68a-fdfee9094bd5"
      },
      "source": [
        "!ollama --version"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ollama version is 0.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54819bdf",
        "outputId": "a90a2f11-b9db-467c-981d-f3d41eed00d4"
      },
      "source": [
        "!ollama list"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME             ID              SIZE      MODIFIED      \n",
            "llama2:latest    78e26419b446    3.8 GB    2 minutes ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2055325",
        "outputId": "ea7b73f4-d966-49f7-fcdd-db9d8fb9860d"
      },
      "source": [
        "# Download the llama2 model\n",
        "!ollama pull llama2"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34c75618",
        "outputId": "fa4a9ae9-1d25-4511-ab2d-e560897204e6"
      },
      "source": [
        "!ollama list"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME             ID              SIZE      MODIFIED               \n",
            "llama2:latest    78e26419b446    3.8 GB    Less than a second ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f637baca",
        "outputId": "6e80ddf1-f020-4d91-c2cf-894298e02691"
      },
      "source": [
        "# To ask the llama2 model a question, use the 'ollama run' command.\n",
        "# Replace \"What is the capital of France?\" with your desired question.\n",
        "!ollama run llama2 \"What is the capital of France?\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25h\n",
            "\u001b[?25l\u001b[?25hThe\u001b[?25l\u001b[?25h capital\u001b[?25l\u001b[?25h of\u001b[?25l\u001b[?25h France\u001b[?25l\u001b[?25h is\u001b[?25l\u001b[?25h Paris\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "\n",
            "\u001b[?25l\u001b[?25h"
          ]
        }
      ]
    }
  ]
}